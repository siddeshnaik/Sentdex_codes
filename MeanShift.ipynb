{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MeanShift.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPWRnJgq0DXVOLQFVup71Dp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/siddeshnaik/Sentdex_codes/blob/master/MeanShift.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTaqJqMXtJmU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import style\n",
        "style.use('ggplot')\n",
        "import numpy as np\n",
        "from sklearn.datasets.samples_generator import make_blobs\n",
        "X, y = make_blobs(n_samples=30, centers=3, n_features=2)\n",
        "# X = np.array([[1, 2],\n",
        "#               [1.5, 1.8],\n",
        "#               [5, 8 ],\n",
        "#               [8, 8],\n",
        "#               [1, 0.6],\n",
        "#               [9,11],\n",
        "#               [8,2],\n",
        "#               [10,2],\n",
        "#               [9,3],\n",
        "#               [8,2],\n",
        "#               [10,2],\n",
        "#               [9,3]])\n",
        "\n",
        "# plt.scatter(X[:,0], X[:,1], s=150)\n",
        "# plt.show()\n",
        "\n",
        "colors = 10*[\"g\",\"r\",\"c\",\"b\",\"k\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtX3Dx6ZzYAr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "1. Start at every datapoint as a cluster center\n",
        "\n",
        "2. take mean of radius around cluster, setting that as new cluster center\n",
        "\n",
        "3. Repeat #2 until convergence.\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "class Mean_Shift:\n",
        "    def __init__(self, radius = None, radius_norm_step = 100):\n",
        "        self.radius = radius\n",
        "        self.radius_norm_step = radius_norm_step\n",
        "    \n",
        "    def fit(self,data):\n",
        "\n",
        "        if self.radius == None:\n",
        "            all_data_centroid = np.average(data,axis=0)\n",
        "            all_data_norm = np.linalg.norm(all_data_centroid)\n",
        "            self.radius = all_data_norm/self.radius_norm_step\n",
        "            print(self.radius)\n",
        "\n",
        "        centroids = {}\n",
        "\n",
        "        for i in range(len(data)):\n",
        "            centroids[i] = data[i]\n",
        "\n",
        "        weights = [i for i in range(self.radius_norm_step)][::-1]    \n",
        "        while True:\n",
        "            new_centroids = []\n",
        "            for i in centroids:\n",
        "                in_bandwidth = []\n",
        "                centroid = centroids[i]\n",
        "                \n",
        "                for featureset in data:\n",
        "\n",
        "                    distance = np.linalg.norm(featureset-centroid)\n",
        "                    if distance == 0:\n",
        "                        distance = 0.00000000001\n",
        "                    weight_index = int(distance/self.radius)\n",
        "                    if weight_index > self.radius_norm_step-1:\n",
        "                        weight_index = self.radius_norm_step-1\n",
        "\n",
        "                    to_add = (weights[weight_index]**2)*[featureset]\n",
        "                    in_bandwidth +=to_add\n",
        "\n",
        "                new_centroid = np.average(in_bandwidth,axis=0)\n",
        "                new_centroids.append(tuple(new_centroid))\n",
        "\n",
        "            uniques = sorted(list(set(new_centroids)))\n",
        "\n",
        "            to_pop = []\n",
        "\n",
        "            for i in uniques:\n",
        "                for ii in [i for i in uniques]:\n",
        "                    if i == ii:\n",
        "                        pass\n",
        "                    elif np.linalg.norm(np.array(i)-np.array(ii)) <= self.radius:\n",
        "                        #print(np.array(i), np.array(ii))\n",
        "                        to_pop.append(ii)\n",
        "                        break\n",
        "\n",
        "            for i in to_pop:\n",
        "                try:\n",
        "                    uniques.remove(i)\n",
        "                except:\n",
        "                    pass\n",
        "\n",
        "            prev_centroids = dict(centroids)\n",
        "            centroids = {}\n",
        "            for i in range(len(uniques)):\n",
        "                centroids[i] = np.array(uniques[i])\n",
        "\n",
        "            optimized = True\n",
        "\n",
        "            for i in centroids:\n",
        "                if not np.array_equal(centroids[i], prev_centroids[i]):\n",
        "                    optimized = False\n",
        "\n",
        "            if optimized:\n",
        "                break\n",
        "            \n",
        "        self.centroids = centroids\n",
        "        self.classifications = {}\n",
        "\n",
        "        for i in range(len(self.centroids)):\n",
        "            self.classifications[i] = []\n",
        "            \n",
        "        for featureset in data:\n",
        "            #compare distance to either centroid\n",
        "            distances = [np.linalg.norm(featureset-self.centroids[centroid]) for centroid in self.centroids]\n",
        "            #print(distances)\n",
        "            classification = (distances.index(min(distances)))\n",
        "\n",
        "            # featureset that belongs to that cluster\n",
        "            self.classifications[classification].append(featureset)\n",
        "\n",
        "\n",
        "    def predict(self,data):\n",
        "        #compare distance to either centroid\n",
        "        distances = [np.linalg.norm(data-self.centroids[centroid]) for centroid in self.centroids]\n",
        "        classification = (distances.index(min(distances)))\n",
        "        return classification"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLSmDNCV7Uy2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = Mean_Shift()\n",
        "clf.fit(X)\n",
        "\n",
        "centroids = clf.centroids\n",
        "print(centroids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7ftYq3V7dsJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for classification in clf.classifications:\n",
        "    color = colors[classification]\n",
        "    for featureset in clf.classifications[classification]:\n",
        "        plt.scatter(featureset[0],featureset[1], marker = \"x\", color=color, s=150, linewidths = 5, zorder = 10)\n",
        "\n",
        "for c in centroids:\n",
        "    plt.scatter(centroids[c][0],centroids[c][1], color='k', marker = \"*\", s=150, linewidths = 5)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9axRYQt8Jcj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}